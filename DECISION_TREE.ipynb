{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is a Decision Tree, and how does it work for classification?\n",
        "\n",
        "Answer:\n",
        "A Decision Tree is a supervised machine learning model that predicts a class by splitting data into branches based on feature values.\n",
        "\n",
        "How it works:\n",
        "\n",
        "Select the best feature to split the data (using Gini or Entropy).\n",
        "\n",
        "Create decision nodes and branches.\n",
        "\n",
        "Continue splitting until the tree reaches pure leaves or max depth.\n",
        "\n",
        "For classification â†’ leaf node gives the predicted class.\n",
        "\n",
        "It mimics human decision-making, which makes it easy to interpret.\n",
        "\n",
        "Q2. Gini Impurity vs Entropy â€” How they impact splits\n",
        "\n",
        "Answer:\n",
        "\n",
        "Gini Impurity\n",
        "ğº\n",
        "=\n",
        "1\n",
        "âˆ’\n",
        "âˆ‘\n",
        "ğ‘\n",
        "ğ‘–\n",
        "2\n",
        "G=1âˆ’âˆ‘p\n",
        "i\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "Measures how mixed the classes are.\n",
        "\n",
        "Entropy\n",
        "ğ»\n",
        "=\n",
        "âˆ’\n",
        "âˆ‘\n",
        "ğ‘\n",
        "ğ‘–\n",
        "log\n",
        "â¡\n",
        "2\n",
        "(\n",
        "ğ‘\n",
        "ğ‘–\n",
        ")\n",
        "H=âˆ’âˆ‘p\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        "log\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "(p\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        ")\n",
        "\n",
        "Measures uncertainty in the dataset.\n",
        "\n",
        "Impact on Decision Tree:\n",
        "\n",
        "Lower impurity â†’ better split.\n",
        "\n",
        "Gini is faster â†’ used by default.\n",
        "\n",
        "Entropy gives more balanced splits but takes slightly more time.\n",
        "\n",
        "Q3. Pre-Pruning vs Post-Pruning\n",
        "\n",
        "Answer:\n",
        "\n",
        "Pre-Pruning\n",
        "\n",
        "Stop tree growth early using:\n",
        "\n",
        "max_depth\n",
        "\n",
        "min_samples_split\n",
        "\n",
        "min_samples_leaf\n",
        "\n",
        "Advantage:\n",
        "Prevents overfitting early and reduces training time.\n",
        "\n",
        "Post-Pruning\n",
        "\n",
        "Build full tree â†’ then prune back unnecessary branches.\n",
        "\n",
        "Advantage:\n",
        "Better accuracy because tree first learns full patterns before removal.\n",
        "\n",
        "Q4. What is Information Gain? Why important?\n",
        "\n",
        "Answer:\n",
        "Information Gain measures how much impurity is reduced after a split:\n",
        "\n",
        "ğ¼\n",
        "ğº\n",
        "=\n",
        "ğ¼\n",
        "ğ‘š\n",
        "ğ‘\n",
        "ğ‘¢\n",
        "ğ‘Ÿ\n",
        "ğ‘–\n",
        "ğ‘¡\n",
        "ğ‘¦\n",
        "ğ‘\n",
        "ğ‘\n",
        "ğ‘Ÿ\n",
        "ğ‘’\n",
        "ğ‘›\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "âˆ‘\n",
        "ğ‘›\n",
        "ğ‘–\n",
        "ğ‘›\n",
        "ğ¼\n",
        "ğ‘š\n",
        "ğ‘\n",
        "ğ‘¢\n",
        "ğ‘Ÿ\n",
        "ğ‘–\n",
        "ğ‘¡\n",
        "ğ‘¦\n",
        "ğ‘\n",
        "â„\n",
        "ğ‘–\n",
        "ğ‘™\n",
        "ğ‘‘\n",
        "IG=Impurity\n",
        "parent\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’âˆ‘\n",
        "n\n",
        "n\n",
        "i\n",
        "\tâ€‹\n",
        "\n",
        "\tâ€‹\n",
        "\n",
        "Impurity\n",
        "child\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "Importance:\n",
        "\n",
        "Allows tree to pick the best feature at every step\n",
        "\n",
        "Ensures splits give highest improvement in classification\n",
        "\n",
        "Q5. Real-world applications + advantages + limitations\n",
        "\n",
        "Answer:\n",
        "\n",
        "Applications\n",
        "\n",
        "Medical diagnosis\n",
        "\n",
        "Fraud detection\n",
        "\n",
        "Customer churn prediction\n",
        "\n",
        "Loan approval\n",
        "\n",
        "Manufacturing defect detection\n",
        "\n",
        "Advantages\n",
        "\n",
        "Easy to understand\n",
        "\n",
        "No need for scaling\n",
        "\n",
        "Works with categorical + numerical data\n",
        "\n",
        "Limitations\n",
        "\n",
        "Overfitting\n",
        "\n",
        "High variance\n",
        "\n",
        "Sensitive to small changes in data"
      ],
      "metadata": {
        "id": "RwTGY9puHNzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Decision Tree Classifier (Gini) on Iris Dataset"
      ],
      "metadata": {
        "id": "n-pZTJZBHRlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='gini')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "id": "nFgzyhVfHTlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Compare Fully-grown Tree vs max_depth=3"
      ],
      "metadata": {
        "id": "kuWyOPfvHWoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Full tree\n",
        "full_tree = DecisionTreeClassifier()\n",
        "full_tree.fit(X_train, y_train)\n",
        "full_acc = accuracy_score(y_test, full_tree.predict(X_test))\n",
        "\n",
        "# Pruned tree\n",
        "pruned_tree = DecisionTreeClassifier(max_depth=3)\n",
        "pruned_tree.fit(X_train, y_train)\n",
        "pruned_acc = accuracy_score(y_test, pruned_tree.predict(X_test))\n",
        "\n",
        "print(\"Full Tree Accuracy:\", full_acc)\n",
        "print(\"Max Depth 3 Accuracy:\", pruned_acc)\n"
      ],
      "metadata": {
        "id": "-JB9Ftq-HYfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Decision Tree Regressor on California Housing"
      ],
      "metadata": {
        "id": "OlWRLHZpHeOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred))\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "id": "QX4kzKdRHfrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. GridSearchCV for max_depth & min_samples_split"
      ],
      "metadata": {
        "id": "gyaDBOufHh-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "params = {\n",
        "    \"max_depth\": [2, 3, 4, 5, None],\n",
        "    \"min_samples_split\": [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "id": "jA5y5MQvHjRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Healthcare disease prediction using Decision Tree\n",
        "\n",
        "Answer:\n",
        "\n",
        "1. Handling Missing Values\n",
        "\n",
        "For numerical features â†’ impute using mean/median\n",
        "\n",
        "For categorical features â†’ use mode imputation\n",
        "\n",
        "Tools:\n",
        "\n",
        "SimpleImputer(strategy='median')\n",
        "SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "2. Encoding Categorical Features\n",
        "\n",
        "Use:\n",
        "\n",
        "OneHotEncoder\n",
        "\n",
        "LabelEncoder (if ordinal)\n",
        "\n",
        "3. Train Decision Tree Model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "4. Tune Hyperparameters\n",
        "\n",
        "Use GridSearchCV:\n",
        "\n",
        "Parameters:\n",
        "\n",
        "max_depth\n",
        "\n",
        "min_samples_split\n",
        "\n",
        "min_samples_leaf\n",
        "\n",
        "criterion (gini/entropy)\n",
        "\n",
        "5. Evaluate Model\n",
        "\n",
        "Use:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall (important for healthcare!)\n",
        "\n",
        "F1 score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "6. Business Value\n",
        "\n",
        "Early disease detection\n",
        "\n",
        "Better patient risk prediction\n",
        "\n",
        "Helps doctors make decisions faster\n",
        "\n",
        "Reduces medical costs\n",
        "\n",
        "Improves patient survival rate"
      ],
      "metadata": {
        "id": "HUm-v0FkHmfI"
      }
    }
  ]
}